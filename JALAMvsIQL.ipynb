{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02bb50c6",
   "metadata": {},
   "source": [
    "# JAL-AM vs IQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70132e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from multiprocessing import cpu_count\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from games.foraging import Foraging\n",
    "from agents.jalam_agent import JALAMAgent, JALAMAgentConfig\n",
    "from agents.iql_agent import IQLAgent, IQLAgentConfig\n",
    "\n",
    "from auxiliar.explorative_agents_training_and_eval import entrenar_agente_tarea, eval_experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a855c077",
   "metadata": {},
   "source": [
    "## Definir configuración, entrenar y evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b3ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraciones de los juegos\n",
    "game_config = [\n",
    "        \"Foraging-5x5-2p-1f-v3\",\n",
    "        \"Foraging-5x5-3p-1f-coop-v3\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cc7e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = {\n",
    "    'fast_jalam_vs_iql_0': {\n",
    "        'game': game_config[0],\n",
    "        'agent_0': IQLAgentConfig(\n",
    "            start_epsilon=1.0,          # Epsilon inicial\n",
    "            min_epsilon=0.1,            # Mínimo valor que puede tomar Epsilon\n",
    "            epsilon_decay = 0.9997,     # Decaimiento lineal\n",
    "            alpha=0.15,                 # Taza de aprendizaje\n",
    "            gamma=0.95,                 # Factor de descuento\n",
    "            learn=True,                 # Variable que determina si se esta en étapa de exploración o no (update y Epsilon-greedy o política greedy)\n",
    "            seed=1                      # Semilla para la aleatoriedad\n",
    "        ),\n",
    "        'agent_1': JALAMAgentConfig(\n",
    "            start_epsilon=1.0,          # Epsilon inicial\n",
    "            min_epsilon=0.1,            # Mínimo valor que puede tomar Epsilon\n",
    "            epsilon_decay = 0.9997,     # Decaimiento lineal\n",
    "            alpha=0.15,                 # Taza de aprendizaje\n",
    "            gamma=0.95,                 # Factor de descuento\n",
    "            learn=True,                 # Variable que determina si se esta en étapa de exploración o no (update y Epsilon-greedy o política greedy)\n",
    "            seed=1                      # Semilla para la aleatoriedad\n",
    "        ),\n",
    "        'train_config': {\n",
    "            'episodes': 1500,\n",
    "            'iterations': 10,\n",
    "        }\n",
    "    },\n",
    "    'fast_jalam_coop_1': {\n",
    "        'game': game_config[0],\n",
    "        'agent_0': IQLAgentConfig(\n",
    "            start_epsilon=1.0,      # Epsilon inicial\n",
    "            min_epsilon=0.1,        # Mínimo valor que puede tomar Epsilon\n",
    "            epsilon_decay = 0.9999, # Decaimiento lineal\n",
    "            alpha=0.2,              # Taza de aprendizaje\n",
    "            gamma=0.95,             # Factor de descuento\n",
    "            learn=True,             # Variable que determina si se esta en étapa de exploración o no (update y Epsilon-greedy o política greedy)\n",
    "            seed=1                  # Semilla para la aleatoriedad\n",
    "        ),\n",
    "        'agent_1': JALAMAgentConfig(\n",
    "            start_epsilon=1.0,      # Epsilon inicial\n",
    "            min_epsilon=0.1,        # Mínimo valor que puede tomar Epsilon\n",
    "            epsilon_decay = 0.9999, # Decaimiento lineal\n",
    "            alpha=0.2,              # Taza de aprendizaje\n",
    "            gamma=0.95,             # Factor de descuento\n",
    "            learn=True,             # Variable que determina si se esta en étapa de exploración o no (update y Epsilon-greedy o política greedy)\n",
    "            seed=1                  # Semilla para la aleatoriedad\n",
    "        ),\n",
    "        'agent_2': JALAMAgentConfig(\n",
    "            start_epsilon=1.0,      # Epsilon inicial\n",
    "            min_epsilon=0.1,        # Mínimo valor que puede tomar Epsilon\n",
    "            epsilon_decay = 0.15, # Decaimiento lineal\n",
    "            alpha=0.2,              # Taza de aprendizaje\n",
    "            gamma=0.95,             # Factor de descuento\n",
    "            learn=True,             # Variable que determina si se esta en étapa de exploración o no (update y Epsilon-greedy o política greedy)\n",
    "            seed=1                  # Semilla para la aleatoriedad\n",
    "        ),\n",
    "        'train_config': {\n",
    "            'episodes': 2000,\n",
    "            'iterations': 15,\n",
    "        }\n",
    "    },\n",
    "    'fast_jalam_coop_2': {\n",
    "        'game': game_config[1],\n",
    "        'agent_0': IQLAgentConfig(\n",
    "            start_epsilon=1.0,      # Epsilon inicial\n",
    "            min_epsilon=0.1,        # Mínimo valor que puede tomar Epsilon\n",
    "            epsilon_decay = 0.9999, # Decaimiento lineal\n",
    "            alpha=0.2,              # Taza de aprendizaje\n",
    "            gamma=0.95,             # Factor de descuento\n",
    "            learn=True,             # Variable que determina si se esta en étapa de exploración o no (update y Epsilon-greedy o política greedy)\n",
    "            seed=1                  # Semilla para la aleatoriedad\n",
    "        ),\n",
    "        'agent_1': JALAMAgentConfig(\n",
    "            start_epsilon=1.0,      # Epsilon inicial\n",
    "            min_epsilon=0.1,        # Mínimo valor que puede tomar Epsilon\n",
    "            epsilon_decay = 0.9999, # Decaimiento lineal\n",
    "            alpha=0.2,              # Taza de aprendizaje\n",
    "            gamma=0.95,             # Factor de descuento\n",
    "            learn=True,             # Variable que determina si se esta en étapa de exploración o no (update y Epsilon-greedy o política greedy)\n",
    "            seed=1                  # Semilla para la aleatoriedad\n",
    "        ),\n",
    "        'agent_2': JALAMAgentConfig(\n",
    "            start_epsilon=1.0,      # Epsilon inicial\n",
    "            min_epsilon=0.1,        # Mínimo valor que puede tomar Epsilon\n",
    "            epsilon_decay = 0.15, # Decaimiento lineal\n",
    "            alpha=0.2,              # Taza de aprendizaje\n",
    "            gamma=0.95,             # Factor de descuento\n",
    "            learn=True,             # Variable que determina si se esta en étapa de exploración o no (update y Epsilon-greedy o política greedy)\n",
    "            seed=1                  # Semilla para la aleatoriedad\n",
    "        ),\n",
    "        'train_config': {\n",
    "            'episodes': 2000,\n",
    "            'iterations': 15,\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dff84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alias o nombre de los agentes para cada configuración\n",
    "agent_alias = {'fast_jalam_vs_iql_0': {'agent_0': 'IQLAgent',     'agent_1': 'JALAMAgent'},\n",
    "               'fast_jalam_coop_1':   {'agent_0': 'IQLAgent',     'agent_1': 'JALAMAgent_0', 'agent_2': 'JALAMAgent_1'},\n",
    "               'fast_jalam_coop_2':   {'agent_0': 'JALAMAgent_0', 'agent_1': 'JALAMAgent_1', 'agent_2': 'JALAMAgent_2'}}\n",
    "\n",
    "# Clases de los agentes definidas para cada configuración\n",
    "agent_classes = {'fast_jalam_vs_iql_0': {'agent_0': IQLAgent,   'agent_1': JALAMAgent},\n",
    "                 'fast_jalam_coop_1':   {'agent_0': IQLAgent,   'agent_1': JALAMAgent, 'agent_2': JALAMAgent},\n",
    "                 'fast_jalam_coop_2':   {'agent_0': JALAMAgent, 'agent_1': JALAMAgent, 'agent_2': JALAMAgent}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5571e0ca",
   "metadata": {},
   "source": [
    "## Definir experimentos y entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be91bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armar lista de tareas\n",
    "tareas = [(config_id, config, agent_classes[config_id], agent_alias[config_id]) for config_id, config in configurations.items() if config_id]\n",
    "config_keys = [tarea[0] for tarea in tareas]\n",
    "\n",
    "# Número de procesos\n",
    "n_proc = min(len(tareas), cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c0f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPool(n_proc) as pool:\n",
    "    resultados = pool.map(entrenar_agente_tarea, tareas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4d067b",
   "metadata": {},
   "source": [
    "## Evaluar experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a9ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_names = config_keys # Usar nombre de las tareas recién ejecutadas o elegir a mano\n",
    "eval_experiments(experiments_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pettingzoo_games",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
